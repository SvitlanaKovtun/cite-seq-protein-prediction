{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa64508-f306-4c56-8489-b0667b36a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472138\n"
     ]
    }
   ],
   "source": [
    "print(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5deb6ef2-4c9d-45b4-aa83-dbaf46c010e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"7\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"7\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import gc\n",
    "import numpy as np\n",
    "base_dir = \"/home/skovtun/Python_projects/Kaggle/Single cell\"\n",
    "data_dir = os.path.join(base_dir, \"Single_cell_data\")\n",
    "random_state=77\n",
    "os.chdir(\"/home/skovtun/Python_projects/Kaggle/Single cell\")\n",
    "metadata_old = pd.read_csv('Single_cell_data/metadata.csv', index_col = 'cell_id')\n",
    "fix = pd.read_csv('Single_cell_data/metadata_cite_day_2_donor_27678.csv', index_col = 'cell_id')\n",
    "metadata = pd.concat([metadata_old, fix], axis = 0)\n",
    "del fix, metadata_old\n",
    "#cite = pd.read_hdf('Single_cell_data/train_cite_inputs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07821a53-2b53-4627-b802-234b72bdd3e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splitting site to 7 groups based on cell type.\n",
    "# cite_metadata = metadata[metadata['technology'] == 'citeseq']\n",
    "# cell_types = cite_metadata['cell_type'].unique()\n",
    "# base_dir = \"/home/skovtun/Python_projects/Kaggle/Single cell\"\n",
    "# data_dir = os.path.join(base_dir, \"Single_cell_data\")\n",
    "\n",
    "# os.chdir(data_dir)\n",
    "\n",
    "# for cell_type in cell_types:\n",
    "#     print(f\"Processing {cell_type}...\")\n",
    "#     idx = cite_metadata[cite_metadata['cell_type'] == cell_type].index\n",
    "#     valid_ids = idx.intersection(cite.index)\n",
    "#     subset = cite.loc[valid_ids]\n",
    "\n",
    "#     # write directly to file under its own key\n",
    "#     subset.to_parquet(\n",
    "#     f\"X_{cell_type}.parquet\",\n",
    "#     engine=\"pyarrow\",\n",
    "#     index=True,\n",
    "#     coerce_timestamps=\"ms\",\n",
    "#     allow_truncated_timestamps=True,\n",
    "#     version=\"2.6\")\n",
    "#     # free memory immediately\n",
    "#     del subset\n",
    "# os.chdir(base_dir)\n",
    "# import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8d94d0-a577-41f1-be72-1dfcf2a79752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HSC...\n",
      "0.24375638564427693\n",
      "Processing EryP...\n",
      "0.18212833007176718\n",
      "Processing NeuP...\n",
      "0.15617162386576336\n",
      "Processing MasP...\n",
      "0.15948372681935627\n",
      "Processing MkP...\n",
      "0.1079578955968221\n",
      "Processing BP...\n",
      "0.035975893338521324\n",
      "Processing MoP...\n",
      "0.048778629302978514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting cite test to 7 groups based on cell type.\n",
    "# fix has more columns than initial test file, so I am cutting the columns so the datasets \n",
    "#whoud be aligned\n",
    "# import time\n",
    "# evaluation_old = pd.read_hdf('Single_cell_data/test_cite_inputs.h5')\n",
    "# fix = pd.read_hdf('Single_cell_data/test_cite_inputs_day_2_donor_27678.h5')\n",
    "# common_cols = evaluation_old.columns\n",
    "# fix_aligned = fix[common_cols]\n",
    "# cite_evaluation = pd.concat([evaluation_old,fix_aligned], axis = 0)\n",
    "# del evaluation_old, fix\n",
    "# cite_metadata = metadata[metadata['technology'] == 'citeseq']\n",
    "# cell_types = cite_metadata['cell_type'].unique()\n",
    "# base_dir = \"/home/skovtun/Python_projects/Kaggle/Single cell\"\n",
    "# data_dir = os.path.join(base_dir, \"Single_cell_data\")\n",
    "\n",
    "# os.chdir(data_dir)\n",
    "# for cell_type in cell_types:\n",
    "#     print(f\"Processing {cell_type}...\")\n",
    "#     start_time = time.time()\n",
    "#     idx = cite_metadata[cite_metadata['cell_type'] == cell_type].index\n",
    "#     valid_ids = idx.intersection(cite_evaluation.index)\n",
    "#     subset = cite_evaluation.loc[valid_ids]\n",
    "\n",
    "#     # write directly to file under its own key\n",
    "#     subset.to_parquet(\n",
    "#     f\"X_eval{cell_type}.parquet\",\n",
    "#     engine=\"pyarrow\",\n",
    "#     index=True,\n",
    "#     coerce_timestamps=\"ms\",\n",
    "#     allow_truncated_timestamps=True,\n",
    "#     version=\"2.6\")\n",
    "#     print((time.time() - start_time)/60)\n",
    "#     # free memory immediately\n",
    "#     del subset\n",
    "\n",
    "# os.chdir(base_dir)\n",
    "# import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ca624-654b-4841-ab83-8ee732c8a342",
   "metadata": {},
   "source": [
    "BP has only ~150 cells in both train and evaluation sets, so I just add BP cells I need to evaluate to my HSC model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530acecf-6714-4197-b870-da1cfb95847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_dir)\n",
    "targets = pd.read_hdf('train_cite_targets.h5') #all type of cells\n",
    "inputs1 = pd.read_parquet('X_HSC.parquet')\n",
    "inputs2 = pd.read_parquet('X_MasP.parquet')\n",
    "inputs3 = pd.read_parquet('X_MkP.parquet')\n",
    "inputs4 = pd.read_parquet('X_MoP.parquet')\n",
    "inputs5 = pd.read_parquet('X_NeuP.parquet')\n",
    "inputs6 = pd.read_parquet('X_BP.parquet')\n",
    "inputs7 = pd.read_parquet('X_EryP.parquet')\n",
    "\n",
    "inputs = pd.concat([inputs1,inputs2,inputs3,inputs4,inputs5,inputs6, inputs7], axis = 0)\n",
    "del inputs1,inputs2,inputs3,inputs4,inputs5,inputs6,inputs7\n",
    "\n",
    "evaluation1 = pd.read_parquet('X_evalHSC.parquet')\n",
    "evaluation2 = pd.read_parquet('X_evalMasP.parquet')\n",
    "evaluation3 = pd.read_parquet('X_evalMkP.parquet')\n",
    "evaluation4 = pd.read_parquet('X_evalMoP.parquet')\n",
    "evaluation5 = pd.read_parquet('X_evalNeuP.parquet')\n",
    "evaluation6 = pd.read_parquet('X_evalBP.parquet')\n",
    "evaluation7 = pd.read_parquet('X_evalEryP.parquet')\n",
    "evaluation = pd.concat([evaluation1,evaluation2,evaluation3,evaluation4,evaluation5,evaluation6,evaluation7], axis=0)\n",
    "\n",
    "del evaluation1,evaluation2,evaluation3,evaluation4,evaluation5,evaluation6,evaluation7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0590b-b332-424b-bc29-19ff4d4ce350",
   "metadata": {},
   "source": [
    "Get relevant columns for all targets using external file from https://www.biolegend.com/en-us/totalseq/barcode-lookup. The rest will be compressed using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8dabef3-af2b-4157-aeff-d8aa00b13bab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m ens_gene_ids = \u001b[38;5;28mlist\u001b[39m(h_protein_barcodes[\u001b[33m'\u001b[39m\u001b[33mEnsembl Gene Id\u001b[39m\u001b[33m'\u001b[39m].unique())\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m barcode\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m clean_input_cols = [c.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43minputs\u001b[49m.columns]\n\u001b[32m     13\u001b[39m eval_input_cols = [c.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m evaluation.columns]\n\u001b[32m     14\u001b[39m inputs.columns = clean_input_cols\n",
      "\u001b[31mNameError\u001b[39m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(data_dir)\n",
    "#Getting info about gene barcodes relevant to proteins from an external file and choosing these colums\n",
    "# to get corresponding columns from input data to use as is in modeling. The rest will be compressed \n",
    "# using pca\n",
    "targets = pd.read_hdf('train_cite_targets.h5') #all type of cells\n",
    "barcode = pd.read_csv('Totalseq_a.csv')\n",
    "proteins = targets.columns\n",
    "all_protein_barcodes = barcode[barcode['Description'].isin(proteins)].sort_values('Description')\n",
    "h_protein_barcodes = all_protein_barcodes[all_protein_barcodes['Reactivity'].str.contains('Human')]\n",
    "ens_gene_ids = list(h_protein_barcodes['Ensembl Gene Id'].unique())\n",
    "del barcode\n",
    "clean_input_cols = [c.split('_')[0] for c in inputs.columns]\n",
    "eval_input_cols = [c.split('_')[0] for c in evaluation.columns]\n",
    "inputs.columns = clean_input_cols\n",
    "evaluation.columns = eval_input_cols\n",
    "common_cols = list(set(ens_gene_ids)&set(inputs.columns))\n",
    "pca_cols = list(set(inputs.columns) - set(common_cols))\n",
    "assert(clean_input_cols == eval_input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eabec92-2ced-46c0-9892-d27b512e6b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ens_gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d65f48-daad-46f9-83d5-4ab7ee59fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexes of the cell type we are working\n",
    "eval_idx = evaluation.index\n",
    "idx = inputs.index\n",
    "# choosing the same rows form targets\n",
    "valid_ids = idx.intersection(targets.index)\n",
    "y = targets.loc[valid_ids]\n",
    "# random split to train_test\n",
    "rng = np.random.default_rng(77)\n",
    "shuffled_idx = rng.permutation(valid_ids)\n",
    "split_ratio = 0.8\n",
    "split_point = int(len(shuffled_idx) * split_ratio)\n",
    "train_idx = shuffled_idx[:split_point]\n",
    "test_idx = shuffled_idx[split_point:]\n",
    "inputs_train, inputs_test = inputs.loc[train_idx], inputs.loc[test_idx]\n",
    "inputs_train_to_compress = inputs_train[pca_cols]\n",
    "inputs_train_orig = inputs_train[common_cols]\n",
    "inputs_test_to_compress = inputs_test[pca_cols]\n",
    "inputs_test_orig = inputs_test[common_cols]\n",
    "y_train, y_test = y.loc[train_idx], y.loc[test_idx]\n",
    "\n",
    "eval_orig = evaluation[common_cols]\n",
    "eval_to_compress = evaluation[pca_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62c517f-7d12-4c96-92d0-ffb2036f1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save memory, deleting targets, inputs, evaluation\n",
    "del targets, inputs, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8f7aac-81ba-4427-ac89-55cad3d07394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_train scaled\n",
      "inputs_test scaled\n",
      "inputs_val scaled\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "inputs_train_scaled = scaler.fit_transform(inputs_train_to_compress)\n",
    "del inputs_train_to_compress\n",
    "print('inputs_train scaled')\n",
    "inputs_test_scaled = scaler.transform(inputs_test_to_compress)\n",
    "del inputs_test_to_compress\n",
    "print('inputs_test scaled')\n",
    "evaluation_scaled = scaler.transform(eval_to_compress)\n",
    "del eval_to_compress\n",
    "print('inputs_val scaled')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e5cce1-a5bd-4c5f-9eb1-071f5ded1d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_train_pca completed\n",
      "0.5527858098347982\n",
      "inputs_test_pca completed\n",
      "0.008547735214233399\n",
      "evaluation_pca completed\n",
      "0.061624594529469806\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=200)\n",
    "inputs_train_pca = pca.fit_transform(inputs_train_scaled)\n",
    "print('inputs_train_pca completed')\n",
    "print((time.time() - start_time)/60)\n",
    "start_time = time.time()\n",
    "inputs_test_pca = pca.transform(inputs_test_scaled)\n",
    "print('inputs_test_pca completed')\n",
    "print((time.time() - start_time)/60)\n",
    "start_time = time.time()\n",
    "evaluation_pca = pca.transform(evaluation_scaled)\n",
    "print('evaluation_pca completed')\n",
    "print((time.time() - start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c9c905-6bac-4f0c-bfa7-79d02579016d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56790, 200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baec3f96-f6ff-4bb9-aa41-674d8e59cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train_all = np.hstack([inputs_train_orig.values, inputs_train_pca])\n",
    "inputs_test_all = np.hstack([inputs_test_orig.values, inputs_test_pca])\n",
    "evaluation_all = np.hstack([eval_orig.values, evaluation_pca])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87166d-0665-4b91-aa2a-2bfe78d6cb7c",
   "metadata": {},
   "source": [
    "Dealing with mixture of original and PCA transformed columns, it's impossible to remove donor effect. I tried linear and non-linear method, but the signal is very strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3428d1-1500-4dd1-9d0b-b48cc076d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "pca_cols = [f'PC{i+1}' for i in range(inputs_train_pca.shape[1])]\n",
    "all_cols = list(inputs_train_orig.columns) + pca_cols\n",
    "print(len(all_cols))   \n",
    "X_train_all = pd.DataFrame(inputs_train_all, index = train_idx, columns = all_cols)\n",
    "X_test_all = pd.DataFrame(inputs_test_all, index = test_idx, columns = all_cols)\n",
    "X_eval_all = pd.DataFrame(evaluation_all, index = eval_idx, columns = all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a9df819-9dba-40ea-8dc3-23876f14d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'donor', 'cell_type', 'technology'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b8e7194-45e8-414b-b573-4c1fe2c1e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train_all, metadata[['day','donor','cell_type']], how = 'left', left_index = True, right_index = True)\n",
    "X_test = pd.merge (X_test_all, metadata[['day','donor','cell_type']], how = 'left', left_index = True, right_index = True)\n",
    "X_eval = pd.merge (X_eval_all, metadata[['day','donor','cell_type']], how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a937878-387d-40e6-b5cc-fed90439d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cell_type'] = X_train['cell_type'].astype('category')\n",
    "X_test['cell_type'] = X_test['cell_type'].astype('category') \n",
    "X_eval['cell_type'] = X_eval['cell_type'].astype('category') \n",
    "\n",
    "X_train_one=pd.get_dummies(X_train, columns=['cell_type'], prefix = 'ct', dummy_na=False)\n",
    "X_test_one=pd.get_dummies(X_test, columns=['cell_type'], prefix = 'ct', dummy_na=False)\n",
    "X_eval_one=pd.get_dummies(X_eval, columns=['cell_type'], prefix = 'ct', dummy_na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27325f97-6014-44be-bff1-5a3c99e1c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# X_train: (n_cells, 301) PCA or features\n",
    "# Y_protein: (n_cells, 140) protein targets as a DataFrame or ndarray\n",
    "# protein_names: length-140 list/Index of protein IDs\n",
    "\n",
    "protein_names = y_train.columns  # if DataFrame\n",
    "\n",
    "stats = []\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "for j, protein in enumerate(protein_names):\n",
    "    y = y_train[protein].values  # shape (n_cells,)\n",
    "\n",
    "    var = np.var(y)\n",
    "    mean = np.mean(y)\n",
    "\n",
    "    # quick baseline difficulty measure\n",
    "    r2 = cross_val_score(\n",
    "        ridge, X_train_one,y_train[protein],\n",
    "        cv=3,\n",
    "        scoring=\"r2\",\n",
    "        n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    stats.append({\"protein\": protein, \"var\": var, \"mean\": mean, \"r2\": r2})\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "stats_df[\"var_bin\"] = pd.qcut(stats_df[\"var\"], 3, labels=[\"low_var\", \"mid_var\", \"high_var\"])\n",
    "stats_df[\"r2_bin\"]  = pd.qcut(stats_df[\"r2\"],  3, labels=[\"hard\", \"medium\", \"easy\"])\n",
    "\n",
    "rep_proteins = []\n",
    "\n",
    "for v in [\"low_var\", \"mid_var\", \"high_var\"]:\n",
    "    for r in [\"hard\", \"medium\", \"easy\"]:\n",
    "        block = stats_df[(stats_df[\"var_bin\"] == v) & (stats_df[\"r2_bin\"] == r)]\n",
    "        if len(block) == 0:\n",
    "            continue\n",
    "        # pick one protein in this cell – e.g. closest to median r2\n",
    "        chosen1 = block.iloc[(block[\"r2\"] - block[\"r2\"].median()).abs().argmin()]\n",
    "        rep_proteins.append(chosen1[\"protein\"])\n",
    "        chosen2 = block.iloc[(block[\"r2\"] - block[\"r2\"].median()).abs().argmax()]\n",
    "        rep_proteins.append(chosen2[\"protein\"])\n",
    "rep_proteins = list(dict.fromkeys(rep_proteins))  # unique, preserve order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78fe222c-fd57-495e-ad3f-5946c00ee824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mouse-IgG2a',\n",
       " 'CD16',\n",
       " 'CD270',\n",
       " 'CD141',\n",
       " 'CD21',\n",
       " 'CD93',\n",
       " 'CD86',\n",
       " 'CD272',\n",
       " 'CD304',\n",
       " 'CD142',\n",
       " 'CD7',\n",
       " 'CD11c',\n",
       " 'CD22',\n",
       " 'CD44',\n",
       " 'CD41']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34f949d1-1c6e-4850-9de2-6fe813ad497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB global model (all cells) + cell_type dummies\n",
    "# Use with xgb.train + early stopping (as in your loop)\n",
    "\n",
    "candidate_params = [\n",
    "    # A) strong default (robust under donor shift)\n",
    "    dict(max_depth=5, min_child_weight=40, subsample=0.80, colsample_bytree=0.40,\n",
    "         learning_rate=0.05, reg_alpha=0.0, reg_lambda=4.0, gamma=0.0),\n",
    "\n",
    "    # B) slightly shallower, more conservative\n",
    "    dict(max_depth=4, min_child_weight=60, subsample=0.75, colsample_bytree=0.45,\n",
    "         learning_rate=0.05, reg_alpha=0.0, reg_lambda=5.0, gamma=0.0),\n",
    "\n",
    "    # C) deeper but controlled by min_child_weight + sampling\n",
    "    dict(max_depth=6, min_child_weight=50, subsample=0.75, colsample_bytree=0.35,\n",
    "         learning_rate=0.04, reg_alpha=0.0, reg_lambda=5.0, gamma=0.0),\n",
    "\n",
    "    # D) strong column subsampling (often helps with correlated PCA/LSI + OHE)\n",
    "    dict(max_depth=5, min_child_weight=50, subsample=0.70, colsample_bytree=0.30,\n",
    "         learning_rate=0.05, reg_alpha=0.0, reg_lambda=5.0, gamma=0.0),\n",
    "\n",
    "    # E) add some L1 sparsity (useful when many weak features)\n",
    "    dict(max_depth=5, min_child_weight=40, subsample=0.80, colsample_bytree=0.40,\n",
    "         learning_rate=0.05, reg_alpha=0.3, reg_lambda=4.0, gamma=0.0),\n",
    "\n",
    "    # F) extra conservative (good baseline when overfitting is suspected)\n",
    "    dict(max_depth=4, min_child_weight=80, subsample=0.70, colsample_bytree=0.35,\n",
    "         learning_rate=0.06, reg_alpha=0.1, reg_lambda=6.0, gamma=0.0),\n",
    "\n",
    "    # G) slightly higher capacity but regularized\n",
    "    dict(max_depth=6, min_child_weight=60, subsample=0.80, colsample_bytree=0.40,\n",
    "         learning_rate=0.03, reg_alpha=0.0, reg_lambda=6.0, gamma=0.0),\n",
    "\n",
    "    # H) DART option (only if runtime allows; can improve generalization)\n",
    "    dict(booster=\"dart\", max_depth=5, min_child_weight=50, subsample=0.80, colsample_bytree=0.35,\n",
    "         learning_rate=0.05, reg_alpha=0.0, reg_lambda=5.0, gamma=0.0,\n",
    "         rate_drop=0.10, skip_drop=0.50),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a7ce4a4-5499-48b7-909b-4ddf51094372",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def kaggle_mean_cellwise_pearson(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean per-cell Pearson correlation with the rule that constant prediction \n",
    "    should give -1 in correlation\n",
    "    \"\"\"\n",
    "    yt = np.asarray(y_true)\n",
    "    yp = np.asarray(y_pred)\n",
    "    # constant prediction per row -> -1\n",
    "    const_pred = np.all(yp == yp[:, [0]], axis=1)\n",
    "    y_pred_centered = yp - yp.mean(axis=1, keepdims=True)\n",
    "    y_true_centered = yt - yt.mean(axis=1, keepdims=True)\n",
    "    num = np.sum(y_true_centered * y_pred_centered, axis=1)\n",
    "    den = np.sqrt(np.sum(y_true_centered **2, axis=1) * np.sum(y_pred_centered**2, axis=1))\n",
    "    corrs = np.empty(y_true.shape[0], dtype=float)\n",
    "    corrs[const_pred] = -1.0\n",
    "    # Pearson can be calculated\n",
    "    valid = (~const_pred) & (den > 0)\n",
    "    corrs[valid] = num[valid] / den[valid]\n",
    "    # non-constant with zero denominator\n",
    "    corrs[~const_pred & (den == 0)] = np.nan\n",
    "    return np.nanmean(corrs)  \n",
    "    \n",
    "def split_indices_donor(X_df, donor_col=\"donor\"):\n",
    "    \"\"\"\n",
    "    Randomly choose one donor as validation donor.\n",
    "    Split all rows belonging to that donor into validation set;\n",
    "    all remaining rows into training.\n",
    "    \"\"\"\n",
    "    donor = X_df[donor_col].to_numpy()\n",
    "    uniq = np.unique(donor)\n",
    "\n",
    "    # choose a random donor reproducibly\n",
    "    rng = np.random.RandomState(77)\n",
    "    val_donor = rng.choice(uniq)\n",
    "\n",
    "    # select indices\n",
    "    train_idx = np.where(donor != val_donor)[0]\n",
    "    val_idx   = np.where(donor == val_donor)[0]\n",
    "\n",
    "    return train_idx, val_idx, val_donor\n",
    "\n",
    "def to_float32_numpy(df):\n",
    "    \"\"\"\n",
    "    Convert dataframe to float32 numpy (xgb likes float32)\n",
    "    \"\"\"\n",
    "    arr = df.to_numpy()\n",
    "    if arr.dtype != np.float32:\n",
    "        arrn = arr.astype(np.float32, copy=False)\n",
    "    return arrn\n",
    "\n",
    "def predict_best(booster, dmat):\n",
    "    \"\"\"\n",
    "    Predict with a Booster using the best number of trees based on early stopping.\n",
    "    \"\"\"\n",
    "    attrs = booster.attributes() \n",
    "    ntree = int(attrs[\"best_iteration\"]) + 1\n",
    "    if ntree is not None:\n",
    "        return booster.predict(dmat, iteration_range=(0, ntree))\n",
    "    return booster.predict(dmat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94b63894-fd22-4a18-bc1b-888b5fb649eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donor used for split: 13176\n",
      "Train cells: 39034  Val cells: 17756  #rep_proteins: 15\n",
      "#features used (donor excluded): 311\n",
      "01/8  mean_cellwise_corr=0.89871  cand={'max_depth': 5, 'min_child_weight': 40, 'subsample': 0.8, 'colsample_bytree': 0.4, 'learning_rate': 0.05, 'reg_alpha': 0.0, 'reg_lambda': 4.0, 'gamma': 0.0}\n",
      "02/8  mean_cellwise_corr=0.89853  cand={'max_depth': 4, 'min_child_weight': 60, 'subsample': 0.75, 'colsample_bytree': 0.45, 'learning_rate': 0.05, 'reg_alpha': 0.0, 'reg_lambda': 5.0, 'gamma': 0.0}\n",
      "03/8  mean_cellwise_corr=0.89831  cand={'max_depth': 6, 'min_child_weight': 50, 'subsample': 0.75, 'colsample_bytree': 0.35, 'learning_rate': 0.04, 'reg_alpha': 0.0, 'reg_lambda': 5.0, 'gamma': 0.0}\n",
      "04/8  mean_cellwise_corr=0.89849  cand={'max_depth': 5, 'min_child_weight': 50, 'subsample': 0.7, 'colsample_bytree': 0.3, 'learning_rate': 0.05, 'reg_alpha': 0.0, 'reg_lambda': 5.0, 'gamma': 0.0}\n",
      "05/8  mean_cellwise_corr=0.89872  cand={'max_depth': 5, 'min_child_weight': 40, 'subsample': 0.8, 'colsample_bytree': 0.4, 'learning_rate': 0.05, 'reg_alpha': 0.3, 'reg_lambda': 4.0, 'gamma': 0.0}\n",
      "06/8  mean_cellwise_corr=0.89793  cand={'max_depth': 4, 'min_child_weight': 80, 'subsample': 0.7, 'colsample_bytree': 0.35, 'learning_rate': 0.06, 'reg_alpha': 0.1, 'reg_lambda': 6.0, 'gamma': 0.0}\n",
      "07/8  mean_cellwise_corr=0.89870  cand={'max_depth': 6, 'min_child_weight': 60, 'subsample': 0.8, 'colsample_bytree': 0.4, 'learning_rate': 0.03, 'reg_alpha': 0.0, 'reg_lambda': 6.0, 'gamma': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m     dtrain.set_label(Y_tr[:, j])\n\u001b[32m     49\u001b[39m     dvalid.set_label(Y_va[:, j])\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     booster = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     preds[:, j] = predict_best(booster, dvalid)\n\u001b[32m     62\u001b[39m score = kaggle_mean_cellwise_pearson(Y_va, preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/xgboost/training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/xgboost/core.py:2434\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2434\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2437\u001b[39m     )\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2439\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# XGBoost global-parameter tuning for ONE cell type\n",
    "# - Donor used ONLY for splitting \n",
    "# - Train one model per protein in rep_proteins\n",
    "# - Score each candidate param set by Kaggle metric proxy:\n",
    "#       mean over cells of Pearson corr across proteins\n",
    "# - Uses xgboost.train + DMatrix\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "base_params = dict(\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    tree_method=\"hist\",\n",
    "    seed=77,\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "\n",
    "tr_idx, va_idx, used_val_donor = split_indices_donor(X_train_one, donor_col=\"donor\")\n",
    "\n",
    "X_feat = X_train_one.drop(columns=['donor']) \n",
    "X_tr = to_float32_numpy(X_feat.iloc[tr_idx])\n",
    "X_va = to_float32_numpy(X_feat.iloc[va_idx])\n",
    "\n",
    "\n",
    "Y_tr = y_train.loc[X_feat.index[tr_idx], rep_proteins].to_numpy(dtype=np.float32, copy=False)\n",
    "Y_va = y_train.loc[X_feat.index[va_idx], rep_proteins].to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr)\n",
    "dvalid = xgb.DMatrix(X_va)\n",
    "\n",
    "scores = []\n",
    "\n",
    "print(f\"Donor used for split: {used_val_donor}\")\n",
    "print(f\"Train cells: {len(tr_idx)}  Val cells: {len(va_idx)}  #rep_proteins: {len(rep_proteins)}\")\n",
    "print(f\"#features used (donor excluded): {X_tr.shape[1]}\")\n",
    "\n",
    "for k, cand in enumerate(candidate_params, 1):\n",
    "    params = {**base_params, **cand}\n",
    "    preds = np.zeros_like(Y_va, dtype=np.float32)\n",
    "\n",
    "    # train one booster per protein (same params)\n",
    "    for j in range(len(rep_proteins)):\n",
    "        dtrain.set_label(Y_tr[:, j])\n",
    "        dvalid.set_label(Y_va[:, j])\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=20000,\n",
    "            evals=[(dvalid, \"valid\")],\n",
    "            early_stopping_rounds= 200,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        preds[:, j] = predict_best(booster, dvalid)\n",
    "\n",
    "    score = kaggle_mean_cellwise_pearson(Y_va, preds)\n",
    "    scores.append({\"cand\": cand, \"score\": score})\n",
    "\n",
    "    print(f\"{k:02d}/{len(candidate_params)}  mean_cellwise_corr={score:.5f}  cand={cand}\")\n",
    "\n",
    "best = max(scores, key=lambda d: d[\"score\"])\n",
    "\n",
    "print(\"\\nBEST XGB CANDIDATE (global params for this cell type):\")\n",
    "print(f\"mean_cellwise_corr={best['score']:.5f}\")\n",
    "print(best[\"cand\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e908b83f-317b-40b0-8970-822c5240f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_one.drop('donor', axis = 1)\n",
    "X_test =  X_test_one.drop('donor', axis =1)\n",
    "X_eval = X_eval_one.drop('donor', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a77978b-b55b-4f37-aa5c-da4cf964e61f",
   "metadata": {},
   "source": [
    "The leaderboard metric checks:\n",
    "\n",
    "*For each cell, the pattern across all proteins must be correct.*\n",
    "\n",
    "That means each single-target model should produce predictions that are well correlated with the true values across cells — i.e., the variation between cells should match reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3079e862-b5a2-4d4a-a51e-ceeaa00ba69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CD86\n",
      "2 CD274\n",
      "3 CD270\n",
      "4 CD155\n",
      "5 CD112\n",
      "6 CD47\n",
      "7 CD48\n",
      "8 CD40\n",
      "9 CD154\n",
      "10 CD52\n",
      "11 CD3\n",
      "12 CD8\n",
      "13 CD56\n",
      "14 CD19\n",
      "15 CD33\n",
      "16 CD11c\n",
      "17 HLA-A-B-C\n",
      "18 CD45RA\n",
      "19 CD123\n",
      "20 CD7\n",
      "21 CD105\n",
      "22 CD49f\n",
      "23 CD194\n",
      "24 CD4\n",
      "25 CD44\n",
      "26 CD14\n",
      "27 CD16\n",
      "28 CD25\n",
      "29 CD45RO\n",
      "30 CD279\n",
      "31 TIGIT\n",
      "32 Mouse-IgG1\n",
      "33 Mouse-IgG2a\n",
      "34 Mouse-IgG2b\n",
      "35 Rat-IgG2b\n",
      "36 CD20\n",
      "37 CD335\n",
      "38 CD31\n",
      "39 Podoplanin\n",
      "40 CD146\n",
      "41 IgM\n",
      "42 CD5\n",
      "43 CD195\n",
      "44 CD32\n",
      "45 CD196\n",
      "46 CD185\n",
      "47 CD103\n",
      "48 CD69\n",
      "49 CD62L\n",
      "50 CD161\n",
      "51 CD152\n",
      "52 CD223\n",
      "53 KLRG1\n",
      "54 CD27\n",
      "55 CD107a\n",
      "56 CD95\n",
      "57 CD134\n",
      "58 HLA-DR\n",
      "59 CD1c\n",
      "60 CD11b\n",
      "61 CD64\n",
      "62 CD141\n",
      "63 CD1d\n",
      "64 CD314\n",
      "65 CD35\n",
      "66 CD57\n",
      "67 CD272\n",
      "68 CD278\n",
      "69 CD58\n",
      "70 CD39\n",
      "71 CX3CR1\n",
      "72 CD24\n",
      "73 CD21\n",
      "74 CD11a\n",
      "75 CD79b\n",
      "76 CD244\n",
      "77 CD169\n",
      "78 integrinB7\n",
      "79 CD268\n",
      "80 CD42b\n",
      "81 CD54\n",
      "82 CD62P\n",
      "83 CD119\n",
      "84 TCR\n",
      "85 Rat-IgG1\n",
      "86 Rat-IgG2a\n",
      "87 CD192\n",
      "88 CD122\n",
      "89 FceRIa\n",
      "90 CD41\n",
      "91 CD137\n",
      "92 CD163\n",
      "93 CD83\n",
      "94 CD124\n",
      "95 CD13\n",
      "96 CD2\n",
      "97 CD226\n",
      "98 CD29\n",
      "99 CD303\n",
      "100 CD49b\n",
      "101 CD81\n",
      "102 IgD\n",
      "103 CD18\n",
      "104 CD28\n",
      "105 CD38\n",
      "106 CD127\n",
      "107 CD45\n",
      "108 CD22\n",
      "109 CD71\n",
      "110 CD26\n",
      "111 CD115\n",
      "112 CD63\n",
      "113 CD304\n",
      "114 CD36\n",
      "115 CD172a\n",
      "116 CD72\n",
      "117 CD158\n",
      "118 CD93\n",
      "119 CD49a\n",
      "120 CD49d\n",
      "121 CD73\n",
      "122 CD9\n",
      "123 TCRVa7.2\n",
      "124 TCRVd2\n",
      "125 LOX-1\n",
      "126 CD158b\n",
      "127 CD158e1\n",
      "128 CD142\n",
      "129 CD319\n",
      "130 CD352\n",
      "131 CD94\n",
      "132 CD162\n",
      "133 CD85j\n",
      "134 CD23\n",
      "135 CD328\n",
      "136 HLA-E\n",
      "137 CD82\n",
      "138 CD101\n",
      "139 CD88\n",
      "140 CD224\n",
      "Done.\n",
      "Kaggle Pierson correlation train: 0.9253355768254198\n",
      "Kaggle Pierson correlation train: 0.9014217099264067\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "y_pred = pd.DataFrame(index=y_test.index, columns=y_test.columns, dtype=np.float32)\n",
    "y_pred_train = pd.DataFrame(index=y_train.index, columns=y_train.columns, dtype=np.float32)\n",
    "y_pred_eval = pd.DataFrame(index=X_eval.index, columns=y_train.columns, dtype=np.float32)\n",
    "\n",
    "Xtr = to_float32_numpy(X_train)\n",
    "Xte = to_float32_numpy(X_test)\n",
    "Xev = to_float32_numpy(X_eval)\n",
    "\n",
    "dtrain = xgb.DMatrix(Xtr)\n",
    "dtest  = xgb.DMatrix(Xte)\n",
    "deval  = xgb.DMatrix(Xev)\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"tree_method\": \"hist\",   \n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 40,\n",
    "    \"subsample\": 0.88,\n",
    "    \"colsample_bytree\": 0.4,\n",
    "    \"gamma\": 0.0,\n",
    "    \"reg_lambda\": 4.0,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"seed\": 77,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "i = 1\n",
    "for protein in y_train.columns:\n",
    "    print(i, protein)\n",
    "\n",
    "    ytr = y_train[protein].to_numpy(dtype=np.float32)\n",
    "    dtrain.set_label(ytr)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=600,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_pred_train[protein] = booster.predict(dtrain)\n",
    "    y_pred[protein]       = booster.predict(dtest)\n",
    "    y_pred_eval[protein]  = booster.predict(deval)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"Done.\")\n",
    "score = kaggle_mean_cellwise_pearson(y_train, y_pred_train)\n",
    "print(\"Kaggle Pierson correlation train:\", score)\n",
    "score = kaggle_mean_cellwise_pearson(y_test, y_pred)\n",
    "print(\"Kaggle Pierson correlation train:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937aec8c-4515-4272-9d1f-fac072e511cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d37bd1c2-c5d7-45aa-aa8a-d8e980a9830f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CD86\n",
      "0.28791080713272094\n",
      "2 CD274\n",
      "0.3140679637591044\n",
      "3 CD270\n",
      "0.32285065253575645\n",
      "4 CD155\n",
      "0.32880709568659466\n",
      "5 CD112\n",
      "0.343480118115743\n",
      "6 CD47\n",
      "0.33845674991607666\n",
      "7 CD48\n",
      "0.33193631172180177\n",
      "8 CD40\n",
      "0.2993111173311869\n",
      "9 CD154\n",
      "0.3256821910540263\n",
      "10 CD52\n",
      "0.3157497485478719\n",
      "11 CD3\n",
      "0.317780876159668\n",
      "12 CD8\n",
      "0.31485631863276164\n",
      "13 CD56\n",
      "0.31736618677775064\n",
      "14 CD19\n",
      "0.28911630709966024\n",
      "15 CD33\n",
      "0.34928067922592165\n",
      "16 CD11c\n",
      "0.24606310923894245\n",
      "17 HLA-A-B-C\n",
      "0.34258826573689777\n",
      "18 CD45RA\n",
      "0.3456883509953817\n",
      "19 CD123\n",
      "0.338648521900177\n",
      "20 CD7\n",
      "0.29847044150034585\n",
      "21 CD105\n",
      "0.3270050843556722\n",
      "22 CD49f\n",
      "0.3313333710034688\n",
      "23 CD194\n",
      "0.31337769826253253\n",
      "24 CD4\n",
      "0.3154712359110514\n",
      "25 CD44\n",
      "0.33819146553675333\n",
      "26 CD14\n",
      "0.28433096011479697\n",
      "27 CD16\n",
      "0.313196341196696\n",
      "28 CD25\n",
      "0.2972115238507589\n",
      "29 CD45RO\n",
      "0.323922860622406\n",
      "30 CD279\n",
      "0.3123837033907572\n",
      "31 TIGIT\n",
      "0.32310200134913125\n",
      "32 Mouse-IgG1\n",
      "0.3210986256599426\n",
      "33 Mouse-IgG2a\n",
      "0.3146998604138692\n",
      "34 Mouse-IgG2b\n",
      "0.3177544713020325\n",
      "35 Rat-IgG2b\n",
      "0.3190629323323568\n",
      "36 CD20\n",
      "0.295702064037323\n",
      "37 CD335\n",
      "0.3234150052070618\n",
      "38 CD31\n",
      "0.33772261142730714\n",
      "39 Podoplanin\n",
      "0.3210455338160197\n",
      "40 CD146\n",
      "0.3140913327534994\n",
      "41 IgM\n",
      "0.2870743711789449\n",
      "42 CD5\n",
      "0.2987448294957479\n",
      "43 CD195\n",
      "0.3043427030245463\n",
      "44 CD32\n",
      "0.3102193514506022\n",
      "45 CD196\n",
      "0.2962014277776082\n",
      "46 CD185\n",
      "0.31892560720443724\n",
      "47 CD103\n",
      "0.3137153704961141\n",
      "48 CD69\n",
      "0.30264798800150555\n",
      "49 CD62L\n",
      "0.3491337855656942\n",
      "50 CD161\n",
      "0.31516377528508505\n",
      "51 CD152\n",
      "0.32360244592030846\n",
      "52 CD223\n",
      "0.3174416820208232\n",
      "53 KLRG1\n",
      "0.32893691460291546\n",
      "54 CD27\n",
      "0.26499241987864175\n",
      "55 CD107a\n",
      "0.334106703599294\n",
      "56 CD95\n",
      "0.3346645951271057\n",
      "57 CD134\n",
      "0.3161824941635132\n",
      "58 HLA-DR\n",
      "0.3481484373410543\n",
      "59 CD1c\n",
      "0.23318198919296265\n",
      "60 CD11b\n",
      "0.2968163331349691\n",
      "61 CD64\n",
      "0.2880188981691996\n",
      "62 CD141\n",
      "0.31856672366460165\n",
      "63 CD1d\n",
      "0.31922890345255533\n",
      "64 CD314\n",
      "0.31501075824101765\n",
      "65 CD35\n",
      "0.2560511747996012\n",
      "66 CD57\n",
      "0.31606398423512777\n",
      "67 CD272\n",
      "0.3155422608057658\n",
      "68 CD278\n",
      "0.3194419940312703\n",
      "69 CD58\n",
      "0.32416250705718996\n",
      "70 CD39\n",
      "0.25433756510416666\n",
      "71 CX3CR1\n",
      "0.3208985726038615\n",
      "72 CD24\n",
      "0.3165201822916667\n",
      "73 CD21\n",
      "0.28139122724533083\n",
      "74 CD11a\n",
      "0.3442329963048299\n",
      "75 CD79b\n",
      "0.31512882312138873\n",
      "76 CD244\n",
      "0.34170236984888713\n",
      "77 CD169\n",
      "0.32077499230702716\n",
      "78 integrinB7\n",
      "0.32697234948476156\n",
      "79 CD268\n",
      "0.2878461201985677\n",
      "80 CD42b\n",
      "0.2975320895512899\n",
      "81 CD54\n",
      "0.31861867507298786\n",
      "82 CD62P\n",
      "0.26697606245676675\n",
      "83 CD119\n",
      "0.3229216496149699\n",
      "84 TCR\n",
      "0.31896278460820515\n",
      "85 Rat-IgG1\n",
      "0.3162781516710917\n",
      "86 Rat-IgG2a\n",
      "0.31663970549901327\n",
      "87 CD192\n",
      "0.31739578644434613\n",
      "88 CD122\n",
      "0.31453917423884076\n",
      "89 FceRIa\n",
      "0.3099307656288147\n",
      "90 CD41\n",
      "0.31777300039927164\n",
      "91 CD137\n",
      "0.31886839071909584\n",
      "92 CD163\n",
      "0.3181846300760905\n",
      "93 CD83\n",
      "0.326137642065684\n",
      "94 CD124\n",
      "0.3263525168100993\n",
      "95 CD13\n",
      "0.3296715021133423\n",
      "96 CD2\n",
      "0.2749748984972636\n",
      "97 CD226\n",
      "0.30539263089497887\n",
      "98 CD29\n",
      "0.3310825228691101\n",
      "99 CD303\n",
      "0.3234754284222921\n",
      "100 CD49b\n",
      "0.3386685053507487\n",
      "101 CD81\n",
      "0.3433844566345215\n",
      "102 IgD\n",
      "0.2745370984077454\n",
      "103 CD18\n",
      "0.3269919474919637\n",
      "104 CD28\n",
      "0.3173780997594198\n",
      "105 CD38\n",
      "0.33856019179026287\n",
      "106 CD127\n",
      "0.3023679812749227\n",
      "107 CD45\n",
      "0.333483358224233\n",
      "108 CD22\n",
      "0.3066513458887736\n",
      "109 CD71\n",
      "0.34036646684010824\n",
      "110 CD26\n",
      "0.3046704371770223\n",
      "111 CD115\n",
      "0.3220621625582377\n",
      "112 CD63\n",
      "0.3342557032903036\n",
      "113 CD304\n",
      "0.289799964427948\n",
      "114 CD36\n",
      "0.2926695744196574\n",
      "115 CD172a\n",
      "0.27652260462443035\n",
      "116 CD72\n",
      "0.3130833148956299\n",
      "117 CD158\n",
      "0.31887778838475545\n",
      "118 CD93\n",
      "0.3073368986447652\n",
      "119 CD49a\n",
      "0.2761240402857463\n",
      "120 CD49d\n",
      "0.3310391585032145\n",
      "121 CD73\n",
      "0.30122599204381306\n",
      "122 CD9\n",
      "0.32921816110610963\n",
      "123 TCRVa7.2\n",
      "0.3138103644053141\n",
      "124 TCRVd2\n",
      "0.30763525565465294\n",
      "125 LOX-1\n",
      "0.3194030483563741\n",
      "126 CD158b\n",
      "0.3132084608078003\n",
      "127 CD158e1\n",
      "0.3127139767011007\n",
      "128 CD142\n",
      "0.30927108923594154\n",
      "129 CD319\n",
      "0.3135007421175639\n",
      "130 CD352\n",
      "0.30151996612548826\n",
      "131 CD94\n",
      "0.31295963525772097\n",
      "132 CD162\n",
      "0.3348263144493103\n",
      "133 CD85j\n",
      "0.31645932197570803\n",
      "134 CD23\n",
      "0.3214036424954732\n",
      "135 CD328\n",
      "0.19825199445088704\n",
      "136 HLA-E\n",
      "0.3197913328806559\n",
      "137 CD82\n",
      "0.3410307288169861\n",
      "138 CD101\n",
      "0.28939210971196494\n",
      "139 CD88\n",
      "0.3307305137316386\n",
      "140 CD224\n",
      "0.324909241994222\n",
      "Done.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cell_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m eval_results = pd.DataFrame(y_pred_eval, index = eval_idx, columns = y_train.columns)\n\u001b[32m     36\u001b[39m os.chdir(\u001b[33m'\u001b[39m\u001b[33m/home/skovtun/Python_projects/Kaggle/Single cell/Single_cell_data/Eval_cite\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     37\u001b[39m eval_results.to_parquet(\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX_eval_results\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcell_type\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m     engine=\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m     index=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     41\u001b[39m     coerce_timestamps=\u001b[33m\"\u001b[39m\u001b[33mms\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     allow_truncated_timestamps=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     43\u001b[39m     version=\u001b[33m\"\u001b[39m\u001b[33m2.6\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m os.chdir(base_dir)\n",
      "\u001b[31mNameError\u001b[39m: name 'cell_type' is not defined"
     ]
    }
   ],
   "source": [
    "#Final run\n",
    "X = pd.concat([X_train,X_test], axis = 0)\n",
    "y = pd.concat([y_train,y_test], axis = 0)\n",
    "# Convert once (XGBoost prefers float32)\n",
    "Xtr = to_float32_numpy(X)\n",
    "Xev = to_float32_numpy(X_eval)\n",
    "\n",
    "dtrain = xgb.DMatrix(Xtr)\n",
    "deval  = xgb.DMatrix(Xev)\n",
    "\n",
    "y_pred = pd.DataFrame(index=y.index, columns=y.columns, dtype=np.float32)\n",
    "y_pred_eval = pd.DataFrame(index=X_eval.index, columns=y_train.columns, dtype=np.float32)\n",
    "\n",
    "NUM_BOOST_ROUND = 600   \n",
    "\n",
    "i = 1\n",
    "for protein in y_train.columns:\n",
    "    print(i, protein)\n",
    "    start_time = time.time()\n",
    "    ytr = y[protein].to_numpy(dtype=np.float32)\n",
    "    dtrain.set_label(ytr)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=NUM_BOOST_ROUND,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_pred_eval[protein]  = booster.predict(deval)\n",
    "    print((time.time() - start_time)/60)\n",
    "    i += 1\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39f43543-4733-4d78-92f9-4a12c7514cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = pd.DataFrame(y_pred_eval, index = eval_idx, columns = y_train.columns)\n",
    "os.chdir('/home/skovtun/Python_projects/Kaggle/Single cell/Single_cell_data/Eval_cite')\n",
    "eval_results.to_parquet(\n",
    "    f\"X_eval_results.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    index=True,\n",
    "    coerce_timestamps=\"ms\",\n",
    "    allow_truncated_timestamps=True,\n",
    "    version=\"2.6\")\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd5ebb80-11f5-4abc-97e3-0bc9a52f9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>CD86</th>\n",
       "      <th>CD274</th>\n",
       "      <th>CD270</th>\n",
       "      <th>CD155</th>\n",
       "      <th>CD112</th>\n",
       "      <th>CD47</th>\n",
       "      <th>CD48</th>\n",
       "      <th>CD40</th>\n",
       "      <th>CD154</th>\n",
       "      <th>CD52</th>\n",
       "      <th>...</th>\n",
       "      <th>CD94</th>\n",
       "      <th>CD162</th>\n",
       "      <th>CD85j</th>\n",
       "      <th>CD23</th>\n",
       "      <th>CD328</th>\n",
       "      <th>HLA-E</th>\n",
       "      <th>CD82</th>\n",
       "      <th>CD101</th>\n",
       "      <th>CD88</th>\n",
       "      <th>CD224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c2150f55becb</th>\n",
       "      <td>0.231686</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.812562</td>\n",
       "      <td>3.588033</td>\n",
       "      <td>5.017952</td>\n",
       "      <td>7.736794</td>\n",
       "      <td>3.155045</td>\n",
       "      <td>0.248355</td>\n",
       "      <td>0.590760</td>\n",
       "      <td>0.832704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251721</td>\n",
       "      <td>5.143633</td>\n",
       "      <td>0.410741</td>\n",
       "      <td>0.332023</td>\n",
       "      <td>0.104586</td>\n",
       "      <td>0.497953</td>\n",
       "      <td>3.120649</td>\n",
       "      <td>0.408277</td>\n",
       "      <td>1.991138</td>\n",
       "      <td>1.720973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65b7edf8a4da</th>\n",
       "      <td>0.253644</td>\n",
       "      <td>0.350562</td>\n",
       "      <td>0.490690</td>\n",
       "      <td>3.818251</td>\n",
       "      <td>4.713515</td>\n",
       "      <td>5.690071</td>\n",
       "      <td>3.244531</td>\n",
       "      <td>0.247756</td>\n",
       "      <td>0.449191</td>\n",
       "      <td>0.428743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304217</td>\n",
       "      <td>5.043196</td>\n",
       "      <td>0.433041</td>\n",
       "      <td>0.272544</td>\n",
       "      <td>0.083103</td>\n",
       "      <td>0.426059</td>\n",
       "      <td>2.734398</td>\n",
       "      <td>0.421584</td>\n",
       "      <td>2.017819</td>\n",
       "      <td>1.466038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526647a698f8</th>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.217475</td>\n",
       "      <td>0.473151</td>\n",
       "      <td>4.006247</td>\n",
       "      <td>4.708174</td>\n",
       "      <td>4.897419</td>\n",
       "      <td>0.036915</td>\n",
       "      <td>0.199674</td>\n",
       "      <td>0.180025</td>\n",
       "      <td>0.377155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>3.827174</td>\n",
       "      <td>0.327281</td>\n",
       "      <td>0.093029</td>\n",
       "      <td>0.104951</td>\n",
       "      <td>0.490056</td>\n",
       "      <td>4.978968</td>\n",
       "      <td>0.206673</td>\n",
       "      <td>0.925869</td>\n",
       "      <td>2.015836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab8f207a3dec</th>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.067022</td>\n",
       "      <td>0.638049</td>\n",
       "      <td>4.622150</td>\n",
       "      <td>5.969405</td>\n",
       "      <td>8.311825</td>\n",
       "      <td>4.564003</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>0.359654</td>\n",
       "      <td>1.026319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053421</td>\n",
       "      <td>6.102711</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>-0.025552</td>\n",
       "      <td>0.039365</td>\n",
       "      <td>0.721689</td>\n",
       "      <td>3.279583</td>\n",
       "      <td>0.195828</td>\n",
       "      <td>1.776649</td>\n",
       "      <td>1.911211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08df3dcce25c</th>\n",
       "      <td>0.196436</td>\n",
       "      <td>0.248760</td>\n",
       "      <td>0.496539</td>\n",
       "      <td>3.732250</td>\n",
       "      <td>4.257838</td>\n",
       "      <td>8.610499</td>\n",
       "      <td>4.408142</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.529213</td>\n",
       "      <td>0.656816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>5.342353</td>\n",
       "      <td>0.572662</td>\n",
       "      <td>0.180957</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>0.465358</td>\n",
       "      <td>3.274065</td>\n",
       "      <td>0.405459</td>\n",
       "      <td>1.886846</td>\n",
       "      <td>1.688851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id           CD86     CD274     CD270     CD155     CD112      CD47  \\\n",
       "c2150f55becb  0.231686  0.267504  0.812562  3.588033  5.017952  7.736794   \n",
       "65b7edf8a4da  0.253644  0.350562  0.490690  3.818251  4.713515  5.690071   \n",
       "526647a698f8  0.000807  0.217475  0.473151  4.006247  4.708174  4.897419   \n",
       "ab8f207a3dec  0.083865  0.067022  0.638049  4.622150  5.969405  8.311825   \n",
       "08df3dcce25c  0.196436  0.248760  0.496539  3.732250  4.257838  8.610499   \n",
       "\n",
       "gene_id           CD48      CD40     CD154      CD52  ...      CD94     CD162  \\\n",
       "c2150f55becb  3.155045  0.248355  0.590760  0.832704  ...  0.251721  5.143633   \n",
       "65b7edf8a4da  3.244531  0.247756  0.449191  0.428743  ...  0.304217  5.043196   \n",
       "526647a698f8  0.036915  0.199674  0.180025  0.377155  ... -0.000617  3.827174   \n",
       "ab8f207a3dec  4.564003  0.201294  0.359654  1.026319  ... -0.053421  6.102711   \n",
       "08df3dcce25c  4.408142  0.170700  0.529213  0.656816  ...  0.227756  5.342353   \n",
       "\n",
       "gene_id          CD85j      CD23     CD328     HLA-E      CD82     CD101  \\\n",
       "c2150f55becb  0.410741  0.332023  0.104586  0.497953  3.120649  0.408277   \n",
       "65b7edf8a4da  0.433041  0.272544  0.083103  0.426059  2.734398  0.421584   \n",
       "526647a698f8  0.327281  0.093029  0.104951  0.490056  4.978968  0.206673   \n",
       "ab8f207a3dec  0.500713 -0.025552  0.039365  0.721689  3.279583  0.195828   \n",
       "08df3dcce25c  0.572662  0.180957  0.028210  0.465358  3.274065  0.405459   \n",
       "\n",
       "gene_id           CD88     CD224  \n",
       "c2150f55becb  1.991138  1.720973  \n",
       "65b7edf8a4da  2.017819  1.466038  \n",
       "526647a698f8  0.925869  2.015836  \n",
       "ab8f207a3dec  1.776649  1.911211  \n",
       "08df3dcce25c  1.886846  1.688851  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
