{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3dcc49-575d-42f7-be45-cd54e10a29c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121798\n"
     ]
    }
   ],
   "source": [
    "print(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4921055-bef4-4e82-ae9f-f167816e19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tables\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Limit threads for numerical libraries to manage CPU usage\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"7\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"7\"\n",
    "\n",
    "base_dir = \"/home/skovtun/Python_projects/Kaggle/Single_cell/\"\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "random_state = 77\n",
    "\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43acfad6-1b11-446d-b556-88e746bd7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting external file providing the mapping of human genes to their chromosome coordinates on \n",
    "#the GRCh38 genome to use for reducing number of columns for every target.\n",
    "# RAW LINE:\n",
    "# 1\thavana\tgene\t11869\t14409\t.\t+\t.\tgene_id \"ENSG00000223972\"; gene_version \"5\"; gene_name \"DDX11L1\"; gene_source \"havana\"; gene_biotype \"transcribed_unprocessed_pseudogene\";\n",
    "\n",
    "gtf_path = \"Homo_sapiens.GRCh38.98.gtf\"\n",
    "\n",
    "genes = []\n",
    "\n",
    "with open(gtf_path) as f:\n",
    "    for line in f:\n",
    "        #skipping comments\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        #splitting the line\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        if fields[2] != \"gene\":\n",
    "            continue\n",
    "        \n",
    "        chrom = fields[0]\n",
    "        start = int(fields[3])\n",
    "        end = int(fields[4])\n",
    "        \n",
    "        attr = fields[8]\n",
    "        match_id = re.search(r'gene_id \"([^\"]+)\"',attr)\n",
    "        match_name = re.search(r'gene_name \"([^\"]+)\"',attr)\n",
    "        if match_id:\n",
    "            gene_id = match_id.group(1)\n",
    "        else:\n",
    "            continue\n",
    "        if match_name:\n",
    "            gene_name = match_name.group(1)\n",
    "        else:\n",
    "            gene_name = None\n",
    "        \n",
    "        genes.append([gene_id, gene_name, chrom, start, end])\n",
    "\n",
    "gene_df = pd.DataFrame(genes, columns=[\"gene_id\", \"gene_name\", \"chr\", \"start\", \"end\"])\n",
    "mapping = {str(i): f\"chr{i}\" for i in range(1,23)}\n",
    "mapping['X'] = 'chrX'\n",
    "mapping['Y'] = 'chrY'\n",
    "gene_df['chr'] = gene_df['chr'].map(mapping).fillna(gene_df['chr'])\n",
    "#gene_df['chr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bcbb224-4875-400d-becf-0da414d0c8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60623, 5)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3695775a-c526-40d2-aa09-1b2396508965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23404, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting a list of genes and all coordinates, parsing ATAC Peaks\n",
    "path = \"train_multi_inputs.h5\"\n",
    "cols = pd.read_hdf(path, key=\"train_multi_inputs\", start=0, stop=1).columns\n",
    "path = \"train_multi_targets.h5\"\n",
    "cols_t = pd.read_hdf(path, key = 'train_multi_targets', start = 0, stop=1).columns\n",
    "\n",
    "#From the column names of the multi creating a dataframe with location name, start and end.\n",
    "arr = pd.Series(cols.values)\n",
    "r_p = r'([^:]+):([\\d]+)-([\\d]+)'\n",
    "chr_ranges = arr.str.extract(r_p)\n",
    "chr_ranges.columns = ['chr','start','end']\n",
    "chr_ranges['start'] = chr_ranges['start'].astype(int)\n",
    "chr_ranges['end'] = chr_ranges['end'].astype(int)\n",
    "\n",
    "#Reducing gene_df by choosing onnly chr present in chr_ranges and only gene_id's present as targets.\n",
    "multi_chr = list(chr_ranges['chr'].unique())\n",
    "gene_df_multi = gene_df[gene_df['chr'].isin(multi_chr)]\n",
    "gene_df_multi = gene_df_multi.set_index('gene_id')\n",
    "missing = cols_t.difference(gene_df_multi.index)\n",
    "gene_df_multi = gene_df_multi.loc[gene_df_multi.index.intersection(cols_t)]\n",
    "gene_df_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f0065f-e88b-4b24-bc4f-2bdaebd109be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating maximum amount of features for every target.\n",
    "window = 2000\n",
    "\n",
    "genes = gene_df_multi.loc[gene_df_multi.index.intersection(cols_t)].copy()\n",
    "genes[\"left\"]  = genes[\"start\"] - window\n",
    "genes[\"right\"] = genes[\"end\"]   + window\n",
    "genes[\"gene_id\"] = genes.index  # preserve gene_id as a column\n",
    "\n",
    "chr_ranges = chr_ranges.rename(columns={\n",
    "    \"start\": \"start_peak\",\n",
    "    \"end\":   \"end_peak\"\n",
    "})\n",
    "\n",
    "target_cols = pd.DataFrame()\n",
    "results = []\n",
    "gene_id = []\n",
    "start_peak = []\n",
    "end_peak = []\n",
    "\n",
    "for chr_name, chr_peaks in chr_ranges.groupby(\"chr\"):\n",
    "    sub_genes = genes[genes[\"chr\"] == chr_name]\n",
    "    if sub_genes.empty or chr_peaks.empty:\n",
    "        continue\n",
    "\n",
    "    merged = sub_genes[['gene_id', 'chr', 'left', 'right']].merge(chr_peaks[['chr', 'start_peak', 'end_peak']], on=\"chr\")\n",
    "\n",
    "    mask = (\n",
    "        (merged[\"start_peak\"] >= merged[\"left\"]) &\n",
    "        (merged[\"end_peak\"]   <= merged[\"right\"])\n",
    "    )\n",
    "    m = merged[mask]\n",
    "    results.append(m)\n",
    "        \n",
    "target_cols = pd.concat(results)\n",
    "target_cols['col'] = target_cols['chr'].astype(str)+\":\"+target_cols['start_peak'].astype(str)+\"-\"+target_cols['end_peak'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70046976-9c0a-4288-9b38-6a0bc196b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pca: (105942, 1000) float32 <class 'numpy.memmap'>\n",
      "Y_pca: (105942, 300) float32 <class 'numpy.memmap'>\n"
     ]
    }
   ],
   "source": [
    "#Loading pre-computed features from Notebook 1\n",
    "\n",
    "X_pca = np.load(\"X_csr_1000.npy\", mmap_mode=\"r\")\n",
    "if X_pca.dtype != np.float32:\n",
    "    X_pca = np.asarray(X_pca, dtype=np.float32)\n",
    "\n",
    "n_cells = X_pca.shape[0]\n",
    "\n",
    "Y_pca = np.memmap(\"Y_train_pca_300.f32\", dtype=\"float32\", mode=\"r\", shape=(n_cells, 300))\n",
    "Y_components = np.load(\"Y_ipca_components_300.npy\")\n",
    "Y_mean = np.load(\"Y_ipca_mean.npy\")\n",
    "\n",
    "print(\"X_pca:\", X_pca.shape, X_pca.dtype, type(X_pca))\n",
    "print(\"Y_pca:\", Y_pca.shape, Y_pca.dtype, type(Y_pca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89349dec-6cf5-49d0-b82f-e374c0be3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_importance = np.sum(np.abs(Y_components), axis = 0)\n",
    "ranked_genes = pd.Series(gene_importance, index = cols_t).sort_values(ascending= False)\n",
    "genes_1000 = ranked_genes[:1000]\n",
    "target_cols_1000 = target_cols[target_cols['gene_id'].isin(genes_1000.index)]\n",
    "peaks_1000 = target_cols_1000['col'].unique()\n",
    "with tables.open_file(\"train_multi_inputs.h5\", \"r\") as f:\n",
    "    peaks = f.get_node(\"/train_multi_inputs/axis0\")[:]\n",
    "peaks_d = np.char.decode(peaks, encoding = 'utf-8')\n",
    "peak_to_id = {str(peak): i for i,peak in enumerate(peaks_d)}\n",
    "peaks_1000_idx = sorted(set([peak_to_id[peak] for peak in peaks_1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23d61fa-fa0e-4c2e-a0bc-756c1e7be999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (105942, 228942)\n",
      "Sliced shape: (105942, 15581)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "X_crs = scipy.sparse.load_npz('train_multi_cell.npz')\n",
    "Xgene_1000 = X_crs[:,peaks_1000_idx]\n",
    "print(f\"Original shape: {X_crs.shape}\")\n",
    "print(f\"Sliced shape: {Xgene_1000.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2bf365b-b620-4aec-bd42-35fee01264d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942, 16581)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "X_pca_sparse = csr_matrix(X_csr_1000)\n",
    "X = hstack([X_pca_sparse,Xgene_1000])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d7f0b4d-83c4-4b92-baa9-7e1d43d1b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Splitting and Feature Separation ---\n",
    "# Random Train-Test Split (80/20)\n",
    "with tables.open_file(\"train_multi_inputs.h5\", \"r\") as f:\n",
    "    values = f.get_node(\"/train_multi_inputs/axis1\")[:]\n",
    "cell_names = np.char.decode(values, encoding = 'utf-8')\n",
    "cell_to_id = {str(name): i for i,name in enumerate(cell_names)}\n",
    "\n",
    "\n",
    "random_state=77\n",
    "rng = np.random.default_rng(random_state)\n",
    "shuffled_names = rng.permutation(cell_names)\n",
    "\n",
    "split_point = int(len(shuffled_names) * 0.8)\n",
    "train_names = shuffled_names[:split_point]\n",
    "test_names = shuffled_names[split_point:]\n",
    "\n",
    "train_id = sorted([cell_to_id[name] for name in train_names])\n",
    "test_id = sorted([cell_to_id[name] for name in test_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e5ed97e9-bca0-406a-8b2c-687b070adb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5 Names Count: 105942\n",
      "Meta Rows Count: 105942\n",
      "✅ VERIFIED: The metadata is perfectly aligned with the H5 file.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Length Check: Do we have the same number of rows?\n",
    "print(f\"H5 Names Count: {len(cell_names)}\")\n",
    "print(f\"Meta Rows Count: {len(multi_metadata)}\")\n",
    "assert len(cell_names) == len(multi_metadata), \"❌ Mismatch in length!\"\n",
    "\n",
    "# 2. Order Check: Is every single name in the exact same spot?\n",
    "# We compare the list of names from H5 vs the Index of the Dataframe\n",
    "are_aligned = np.array_equal(multi_metadata.index.values, cell_names)\n",
    "\n",
    "if are_aligned:\n",
    "    print(\"✅ VERIFIED: The metadata is perfectly aligned with the H5 file.\")\n",
    "else:\n",
    "    print(\"❌ WARNING: The order is different!\")\n",
    "    # Show the first mismatch if it failed\n",
    "    for i, (name_h5, name_meta) in enumerate(zip(cell_names, multi_metadata.index)):\n",
    "        if name_h5 != name_meta:\n",
    "            print(f\"First mismatch at row {i}:\")\n",
    "            print(f\"  H5 says:   {name_h5}\")\n",
    "            print(f\"  Meta says: {name_meta}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3d373d-d6ad-4a54-8954-6ef5a8d31116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84753, 16581) (21189, 16581) (84753, 100) (21189, 100)\n"
     ]
    }
   ],
   "source": [
    "inputs_train, inputs_test = X[train_id,:], X[test_id,:]\n",
    "y_subset = Y_pca[:,:100]\n",
    "y_train, y_test = y_subset[train_id,:], y_subset[test_id,:]\n",
    "print(inputs_train.shape, inputs_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82df1dc3-0677-46f6-993e-618c98b08ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading metatdata\n",
    "metadata_old = pd.read_csv('metadata.csv', index_col = 'cell_id')\n",
    "fix = pd.read_csv('metadata_cite_day_2_donor_27678.csv', index_col = 'cell_id')\n",
    "metadata = pd.concat([metadata_old, fix], axis = 0)\n",
    "del metadata_old, fix\n",
    "multi_metadata  = metadata.loc[cell_names,['day','donor']]\n",
    "del metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f0f77a-4e4f-4720-bec0-6bd13b2e5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train, meta_test = multi_metadata.iloc[train_id], multi_metadata.iloc[test_id]\n",
    "day_col_train = meta_train['day'].values.reshape(-1,1)\n",
    "day_sparse_train = csr_matrix(day_col_train)\n",
    "x_train = hstack([inputs_train,day_sparse_train])\n",
    "\n",
    "day_col_test = meta_test['day'].values.reshape(-1,1)\n",
    "day_sparse_test = csr_matrix(day_col_test)\n",
    "x_test = hstack([inputs_test, day_sparse_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86802df6-8daf-4377-8d22-dd3ffc8540cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84753, 16582)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d4beae5-82ec-4325-b3bb-21ea45844d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Randomly Selected Holdout Donor: 32606\n"
     ]
    }
   ],
   "source": [
    "# 1. Choosing a donor to_hold_out\n",
    "donors = meta_train['donor'].unique()\n",
    "rng = np.random.default_rng(seed=77) \n",
    "val_donor = rng.choice(donors)\n",
    "\n",
    "print(f\" Randomly Selected Holdout Donor: {val_donor}\")\n",
    "\n",
    "# 2. Create Indices based on that random choice\n",
    "tr_idx = np.where(meta_train['donor']!= val_donor)[0]\n",
    "tr_mask = (meta_train['donor'] != val_donor).values\n",
    "\n",
    "va_idx = np.where(meta_train['donor'] == val_donor)[0]\n",
    "va_mask = (meta_train['donor'] == val_donor).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
